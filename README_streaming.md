# æµå¼æ‰“åŒ…å‹ç¼©è§£å‹å·¥å…·

ä¸€ä¸ªçœŸæ­£çš„æµå¼å¤„ç†å·¥å…·ï¼Œæ”¯æŒè¾¹å‹ç¼©è¾¹åˆ†ç‰‡ã€è¾¹æ¥æ”¶è¾¹è§£å‹ï¼Œæœ€å¤§åŒ–å†…å­˜æ•ˆç‡ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### æµå¼å¤„ç†æ¶æ„
- **æµå¼å‹ç¼©åˆ†ç‰‡**: å‹ç¼©è¿‡ç¨‹ä¸­ç›´æ¥ç”Ÿæˆåˆ†ç‰‡ï¼Œæ— éœ€ç”Ÿæˆå®Œæ•´æ–‡ä»¶
- **æµå¼è§£å‹**: æ¥æ”¶åˆ†ç‰‡ç«‹å³è§£å‹ï¼Œæ— éœ€ç­‰å¾…å…¨éƒ¨åˆ†ç‰‡
- **å†…å­˜é«˜æ•ˆ**: å›ºå®šå†…å­˜ç¼“å†²åŒºï¼Œå¤„ç†å®Œç«‹å³é‡Šæ”¾
- **å¹¶å‘å¤„ç†**: åˆ©ç”¨å¼‚æ­¥IOå®ç°é«˜æ•ˆå¹¶å‘

### å®Œæ•´åŠŸèƒ½
- âœ… å‹ç¼©åŠŸèƒ½ï¼ˆæ”¯æŒ GZIPã€BZIP2ã€XZã€LZ4ï¼‰
- âœ… è§£å‹åŠŸèƒ½ï¼ˆè‡ªåŠ¨æ£€æµ‹å‹ç¼©æ ¼å¼ï¼‰
- âœ… è‡ªåŠ¨åˆ†ç‰‡ï¼ˆå¯é…ç½®åˆ†ç‰‡å¤§å°ï¼‰
- âœ… æµå¼å¤„ç†ï¼ˆæœ€å°å†…å­˜å ç”¨ï¼‰
- âœ… æ•°æ®å®Œæ•´æ€§ï¼ˆSHA256æ ¡éªŒå’Œï¼‰
- âœ… è¿›åº¦å›è°ƒï¼ˆå®æ—¶ç›‘æ§å¤„ç†è¿›åº¦ï¼‰

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### Python ç‰ˆæœ¬
- Python 3.7+ ï¼ˆéœ€è¦å¼‚æ­¥æ–‡ä»¶IOæ”¯æŒï¼‰

### ä¾èµ–åŒ…
```bash
# å¿…éœ€ä¾èµ–
pip install aiofiles  # å¼‚æ­¥æ–‡ä»¶æ“ä½œ

# å¯é€‰ä¾èµ–ï¼ˆLZ4å‹ç¼©ï¼‰
pip install lz4
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨ - å‹ç¼©å¹¶åˆ†ç‰‡

```python
import asyncio
from streaming_tar_compressor import compress_with_chunks, CompressionType

async def compress_example():
    # å‹ç¼©ç›®å½•å¹¶è‡ªåŠ¨åˆ†ç‰‡ï¼ˆæ¯ç‰‡50MBï¼‰
    chunks = await compress_with_chunks(
        sources=["my_data/", "file.txt"],  # å¯ä»¥æ··åˆæ–‡ä»¶å’Œç›®å½•
        output_prefix="backup",             # ç”Ÿæˆ backup.part0000, backup.part0001...
        compression=CompressionType.GZIP,
        chunk_size=50*1024*1024            # 50MB per chunk
    )
    
    print(f"ç”Ÿæˆäº† {len(chunks)} ä¸ªåˆ†ç‰‡")
    
asyncio.run(compress_example())
```

### 2. åŸºæœ¬ä½¿ç”¨ - ä»åˆ†ç‰‡è§£å‹

```python
import asyncio
from streaming_tar_compressor import decompress_from_chunks, CompressionType

async def decompress_example():
    # ä»åˆ†ç‰‡æ–‡ä»¶è§£å‹
    await decompress_from_chunks(
        input_prefix="backup",           # è¯»å– backup.part0000, backup.part0001...
        output_dir="restored/",          # è§£å‹åˆ°æ­¤ç›®å½•
        compression=CompressionType.GZIP,
        verify_checksum=True             # éªŒè¯æ•°æ®å®Œæ•´æ€§
    )
    
    print("è§£å‹å®Œæˆï¼")
    
asyncio.run(decompress_example())
```

## ğŸ’» é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æµå¼å¤„ç†

```python
import asyncio
from streaming_tar_compressor import StreamingTarCompressor, CompressionType

async def custom_streaming():
    compressor = StreamingTarCompressor(CompressionType.GZIP)
    
    # è‡ªå®šä¹‰åˆ†ç‰‡å¤„ç†
    async for chunk_index, chunk_data in compressor.compress_to_chunks(["data/"]):
        # å¯ä»¥å°†åˆ†ç‰‡å‘é€åˆ°ç½‘ç»œã€å†™å…¥æ•°æ®åº“ç­‰
        print(f"å¤„ç†åˆ†ç‰‡ {chunk_index}: {len(chunk_data)} bytes")
        
        # ç¤ºä¾‹ï¼šå‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨
        # await send_to_remote(chunk_data)
        
        # ç¤ºä¾‹ï¼šåŠ å¯†åä¿å­˜
        # encrypted = encrypt(chunk_data)
        # await save_encrypted_chunk(encrypted)

asyncio.run(custom_streaming())
```

### ç½‘ç»œä¼ è¾“ç¤ºä¾‹

```python
import asyncio
import aiohttp
from streaming_tar_compressor import StreamingTarCompressor

async def compress_and_upload():
    """å‹ç¼©å¹¶ç›´æ¥ä¸Šä¼ åˆ°æœåŠ¡å™¨"""
    compressor = StreamingTarCompressor(CompressionType.GZIP)
    
    async with aiohttp.ClientSession() as session:
        chunk_index = 0
        async for _, chunk_data in compressor.compress_to_chunks(["large_data/"]):
            # ç›´æ¥ä¸Šä¼ åˆ†ç‰‡
            async with session.post(
                f"https://backup.server/upload/chunk/{chunk_index}",
                data=chunk_data
            ) as resp:
                if resp.status == 200:
                    print(f"ä¸Šä¼ åˆ†ç‰‡ {chunk_index} æˆåŠŸ")
            
            chunk_index += 1

async def download_and_decompress():
    """ä»æœåŠ¡å™¨ä¸‹è½½å¹¶è§£å‹"""
    async def download_chunks():
        """ç”Ÿæˆå™¨ï¼šä»æœåŠ¡å™¨ä¸‹è½½åˆ†ç‰‡"""
        async with aiohttp.ClientSession() as session:
            chunk_index = 0
            while True:
                async with session.get(
                    f"https://backup.server/download/chunk/{chunk_index}"
                ) as resp:
                    if resp.status == 404:
                        break  # æ²¡æœ‰æ›´å¤šåˆ†ç‰‡
                    
                    chunk_data = await resp.read()
                    yield chunk_data
                    chunk_index += 1
    
    # æµå¼è§£å‹
    decompressor = StreamingTarCompressor(CompressionType.GZIP)
    await decompressor.decompress_from_chunks(
        download_chunks(),
        "restored_data/"
    )
```

### è¿›åº¦ç›‘æ§

```python
import asyncio
from datetime import datetime
from streaming_tar_compressor import compress_with_chunks, decompress_from_chunks

class ProgressTracker:
    def __init__(self):
        self.start_time = datetime.now()
        self.processed_files = 0
        self.total_bytes = 0
    
    async def compress_progress(self, file_path, size):
        self.processed_files += 1
        self.total_bytes += size
        elapsed = (datetime.now() - self.start_time).total_seconds()
        speed = self.total_bytes / elapsed / 1024 / 1024  # MB/s
        print(f"[å‹ç¼©] {file_path} | å·²å¤„ç†: {self.processed_files} ä¸ªæ–‡ä»¶ | "
              f"é€Ÿåº¦: {speed:.2f} MB/s")
    
    async def decompress_progress(self, file_name, size):
        self.processed_files += 1
        self.total_bytes += size
        print(f"[è§£å‹] {file_name} | å¤§å°: {size:,} bytes")

async def compress_with_progress():
    tracker = ProgressTracker()
    
    chunks = await compress_with_chunks(
        ["large_project/"],
        "project_backup",
        progress_callback=tracker.compress_progress
    )
    
    print(f"\nå‹ç¼©å®Œæˆï¼")
    print(f"æ€»æ–‡ä»¶æ•°: {tracker.processed_files}")
    print(f"æ€»å¤§å°: {tracker.total_bytes / 1024 / 1024:.2f} MB")
    print(f"åˆ†ç‰‡æ•°: {len(chunks)}")

asyncio.run(compress_with_progress())
```

### ç®¡é“å¤„ç†

```python
import asyncio
from streaming_tar_compressor import StreamingTarCompressor

async def pipeline_example():
    """æ¼”ç¤ºç®¡é“å¤„ç†ï¼šå‹ç¼© -> åŠ å¯† -> ä¸Šä¼ """
    
    compressor = StreamingTarCompressor(CompressionType.GZIP)
    
    async def encrypt_chunk(chunk_data):
        """æ¨¡æ‹ŸåŠ å¯†å¤„ç†"""
        # å®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®åŠ å¯†
        return chunk_data[::-1]  # ç®€å•åè½¬ä½œä¸ºç¤ºä¾‹
    
    async def upload_chunk(chunk_index, encrypted_data):
        """æ¨¡æ‹Ÿä¸Šä¼ """
        print(f"ä¸Šä¼ åŠ å¯†åˆ†ç‰‡ {chunk_index}: {len(encrypted_data)} bytes")
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    
    # ç®¡é“å¤„ç†
    async for chunk_index, chunk_data in compressor.compress_to_chunks(["data/"]):
        # æ­¥éª¤1: åŠ å¯†
        encrypted = await encrypt_chunk(chunk_data)
        
        # æ­¥éª¤2: ä¸Šä¼ 
        await upload_chunk(chunk_index, encrypted)
        
        # å†…å­˜ä¼šè‡ªåŠ¨é‡Šæ”¾ï¼Œä¸ä¼šå †ç§¯

asyncio.run(pipeline_example())
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•°æ®æµå‘

```
å‹ç¼©æµç¨‹:
æºæ–‡ä»¶ â†’ Taræµ â†’ å‹ç¼©æµ â†’ åˆ†ç‰‡ç”Ÿæˆå™¨ â†’ è¾“å‡ºå¤„ç†

è§£å‹æµç¨‹:
åˆ†ç‰‡è¾“å…¥ â†’ åˆå¹¶æµ â†’ è§£å‹æµ â†’ Taræå– â†’ ç›®æ ‡æ–‡ä»¶
```

### å†…å­˜ç®¡ç†ç­–ç•¥

1. **å›ºå®šç¼“å†²åŒº**: ä½¿ç”¨1MBçš„å›ºå®šå†…å­˜ç¼“å†²åŒº
2. **æµå¼å¤„ç†**: æ•°æ®å¤„ç†å®Œç«‹å³é‡Šæ”¾ï¼Œä¸ä¿ç•™ä¸­é—´ç»“æœ
3. **å¼‚æ­¥IO**: åˆ©ç”¨å¼‚æ­¥é¿å…é˜»å¡ï¼Œæé«˜å¹¶å‘æ€§èƒ½
4. **ç”Ÿæˆå™¨æ¨¡å¼**: ä½¿ç”¨å¼‚æ­¥ç”Ÿæˆå™¨å®ç°çœŸæ­£çš„æµå¼å¤„ç†

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

### å†…å­˜ä½¿ç”¨
- å³°å€¼å†…å­˜: ~10MBï¼ˆä¸æ–‡ä»¶å¤§å°æ— å…³ï¼‰
- ç¼“å†²åŒºå¤§å°: 1MBï¼ˆå¯è°ƒæ•´ï¼‰
- åˆ†ç‰‡ç¼“å­˜: ä»…å½“å‰å¤„ç†çš„åˆ†ç‰‡

### å¤„ç†é€Ÿåº¦
- ä¸»è¦å—é™äº: ç£ç›˜IOå’Œå‹ç¼©ç®—æ³•
- å¹¶å‘ä¼˜åŠ¿: å¯åŒæ—¶è¿›è¡Œè¯»å–ã€å‹ç¼©ã€å†™å…¥
- ç½‘ç»œå‹å¥½: é€‚åˆè¾¹å‹ç¼©è¾¹ä¼ è¾“åœºæ™¯

## ğŸ›¡ï¸ æ•°æ®å®Œæ•´æ€§

### æ ¡éªŒæœºåˆ¶
- æ¯ä¸ªåˆ†ç‰‡åŒ…å«SHA256æ ¡éªŒå’Œ
- å…ƒæ•°æ®æ–‡ä»¶è®°å½•æ‰€æœ‰åˆ†ç‰‡ä¿¡æ¯
- è§£å‹æ—¶å¯é€‰æ‹©æ€§éªŒè¯æ ¡éªŒå’Œ

### å…ƒæ•°æ®æ ¼å¼

```json
{
  "version": "1.0",
  "total_chunks": 5,
  "chunks": [
    {
      "index": 0,
      "size": 52428800,
      "checksum": "abc123..."
    },
    ...
  ]
}
```

## ğŸ”§ é…ç½®é€‰é¡¹

### å‹ç¼©ç®—æ³•å¯¹æ¯”

| ç®—æ³• | é€Ÿåº¦ | å‹ç¼©ç‡ | CPUä½¿ç”¨ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|---------|----------|
| GZIP | å¿« | ä¸­ | ä¸­ | é€šç”¨ï¼Œå¹³è¡¡é€‰æ‹© |
| BZIP2 | æ…¢ | é«˜ | é«˜ | æ–‡æœ¬æ–‡ä»¶ï¼Œéœ€è¦é«˜å‹ç¼©ç‡ |
| XZ | æœ€æ…¢ | æœ€é«˜ | æœ€é«˜ | é•¿æœŸå­˜æ¡£ï¼Œå¸¦å®½å—é™ |
| LZ4 | æœ€å¿« | ä½ | ä½ | å®æ—¶å¤„ç†ï¼Œä¸´æ—¶æ–‡ä»¶ |

### åˆ†ç‰‡å¤§å°å»ºè®®

- **å±€åŸŸç½‘ä¼ è¾“**: 100-500MB
- **äº’è”ç½‘ä¼ è¾“**: 10-50MB
- **äº‘å­˜å‚¨**: 50-100MB
- **ç§»åŠ¨ç½‘ç»œ**: 5-10MB

## ğŸ“ å®Œæ•´ç¤ºä¾‹

### å¤‡ä»½ç³»ç»Ÿç¤ºä¾‹

```python
import asyncio
from pathlib import Path
from datetime import datetime
from streaming_tar_compressor import (
    compress_with_chunks, 
    decompress_from_chunks,
    CompressionType
)

class BackupSystem:
    def __init__(self, backup_dir="backups/"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
    
    async def create_backup(self, source_dirs, backup_name=None):
        """åˆ›å»ºå¤‡ä»½"""
        if not backup_name:
            backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        backup_path = self.backup_dir / backup_name
        
        print(f"å¼€å§‹å¤‡ä»½åˆ°: {backup_path}")
        
        # å‹ç¼©å¹¶åˆ†ç‰‡
        chunks = await compress_with_chunks(
            sources=source_dirs,
            output_prefix=str(backup_path),
            compression=CompressionType.GZIP,
            chunk_size=100*1024*1024,  # 100MB chunks
            progress_callback=self._backup_progress
        )
        
        print(f"å¤‡ä»½å®Œæˆï¼å…± {len(chunks)} ä¸ªåˆ†ç‰‡")
        
        # åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
        info_file = backup_path.parent / f"{backup_name}.info"
        with open(info_file, 'w') as f:
            f.write(f"Backup Name: {backup_name}\n")
            f.write(f"Date: {datetime.now()}\n")
            f.write(f"Sources: {', '.join(map(str, source_dirs))}\n")
            f.write(f"Chunks: {len(chunks)}\n")
            f.write(f"Total Size: {sum(c.size for c in chunks):,} bytes\n")
        
        return backup_name
    
    async def restore_backup(self, backup_name, restore_dir):
        """æ¢å¤å¤‡ä»½"""
        backup_path = self.backup_dir / backup_name
        
        print(f"å¼€å§‹æ¢å¤å¤‡ä»½: {backup_name}")
        
        await decompress_from_chunks(
            input_prefix=str(backup_path),
            output_dir=restore_dir,
            compression=CompressionType.GZIP,
            verify_checksum=True,
            progress_callback=self._restore_progress
        )
        
        print(f"æ¢å¤å®Œæˆåˆ°: {restore_dir}")
    
    async def _backup_progress(self, file_path, size):
        print(f"  å¤‡ä»½: {file_path}")
    
    async def _restore_progress(self, file_name, size):
        print(f"  æ¢å¤: {file_name}")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    backup_system = BackupSystem()
    
    # åˆ›å»ºå¤‡ä»½
    backup_name = await backup_system.create_backup([
        "project/src/",
        "project/docs/",
        "project/config.json"
    ])
    
    # æ¢å¤å¤‡ä»½
    await backup_system.restore_backup(
        backup_name,
        "restored_project/"
    )

asyncio.run(main())
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å¼‚æ­¥IOè¦æ±‚**: éœ€è¦æ”¯æŒå¼‚æ­¥æ–‡ä»¶æ“ä½œçš„ç¯å¢ƒ
2. **åˆ†ç‰‡é¡ºåº**: è§£å‹æ—¶å¿…é¡»æŒ‰é¡ºåºæä¾›åˆ†ç‰‡
3. **ä¸­æ–­æ¢å¤**: å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ 
4. **å†…å­˜é™åˆ¶**: å•ä¸ªæ–‡ä»¶ä¸èƒ½è¶…è¿‡ç¼“å†²åŒºå¤§å°ï¼ˆé»˜è®¤1MBï¼‰

## ğŸ”® åç»­æ”¹è¿›æ–¹å‘

- [ ] æ–­ç‚¹ç»­ä¼ æ”¯æŒ
- [ ] å¹¶è¡Œå‹ç¼©/è§£å‹
- [ ] åŠ å¯†æ”¯æŒ
- [ ] å¢é‡å¤‡ä»½
- [ ] å‹ç¼©ç‡è‡ªé€‚åº”
- [ ] åˆ†ç‰‡å¤§å°è‡ªåŠ¨ä¼˜åŒ–

## ğŸ“„ è®¸å¯è¯

MIT License
